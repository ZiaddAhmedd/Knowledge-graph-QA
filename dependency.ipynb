{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import coreferee\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import getopt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json \n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the universal dependency for English: https://universaldependencies.org/en/dep/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "nlp.add_pipe(\"merge_noun_chunks\")\n",
    "nlp.add_pipe('coreferee')\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "doc = \"\"\"Lionel Andrés \"Leo\" Messi was born in 24 June 1987. He is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team\"\"\"\n",
    "# doc = \"Presidency of James Madison The presidency of James Madison began on March 4, 1809, when James Madison was inaugurated as President of the United States, and ended on March 4, 1817. Madison, the fourth United States president, took office after defeating Federalist Charles Cotesworth Pinckney decisively in the 1808 presidential election. He was re-elected four years later, defeating DeWitt Clinton in the 1812 election. His presidency was dominated by the War of 1812 with Britain. Madison was succeeded by Secretary of State James Monroe, a fellow member of the Democratic-Republican Party. Madison's presidency was dominated by the effects of the\"\n",
    "# doc = \"Teachers are required to be registered with the Teaching Council; under Section 30 of the Teaching Council Act 2001, a person employed in any capacity in a recognised teaching post - who is not registered with the Teaching Council - may not be paid from Oireachtas funds.\"\n",
    "# doc = \"Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"\"golden anniversary\"\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"\"Super Bowl L\"\"), so that the logo could prominently feature the Arabic numerals 50.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resolve coreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resolve_coreference(text):\n",
    "    doc = nlp(text)\n",
    "    doc_list = list(doc)\n",
    "    doc._.coref_chains.print()\n",
    "    resolving_indecies = []\n",
    "    for _,item in enumerate(doc._.coref_chains):\n",
    "        resolving_indecies.extend(item)\n",
    "        \n",
    "    for word in resolving_indecies:\n",
    "        new_word = \"\"\n",
    "        for index in word:\n",
    "            if doc[index]._.coref_chains.resolve(doc[index]) is not None:\n",
    "                temp = []\n",
    "                for item in doc._.coref_chains.resolve(doc[index]):\n",
    "                    temp.append(str(item))\n",
    "                new_word = \", \".join(temp)\n",
    "            \n",
    "                doc_list[index] = new_word\n",
    "\n",
    "    final_doc = []\n",
    "    for item in doc_list:\n",
    "        final_doc.append(str(item))\n",
    "    return \" \".join(final_doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_who_coreference(text):\n",
    "    doc = nlp(text)\n",
    "    last_subject = \"\"\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"nsubj\":\n",
    "            if token.text in [\"who\", \"which\"]:\n",
    "                words.append(last_subject)\n",
    "            else:\n",
    "                last_subject = token.text\n",
    "                words.append(token.text)\n",
    "        else:\n",
    "            words.append(token.text)\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_context(doc):\n",
    "    text = doc.strip()\n",
    "    # remove any symbols that are not needed but keep the full stop, comma and space\n",
    "    # text = re.sub(r'[^\\w\\s.,]', '', text)\n",
    "    text.replace(\".\", \",\")\n",
    "    resolved_text = resolve_coreference(text)\n",
    "    resolved_text = resolved_text.strip()\n",
    "    resolved_text = resolve_who_coreference(resolved_text)\n",
    "    resolved_text = resolved_text.replace(\"  \", \" \").replace(\" ,\", \",\").replace(\";\",\"\").replace(\" .\", \".\").replace(\"\\n\", \"\")\n",
    "    return resolved_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Lionel Andrés \"Leo\" Messi(0), He(6)\n"
     ]
    }
   ],
   "source": [
    "resolved_doc = preprocess_context(doc)\n",
    "cleaned_doc = nlp(resolved_doc)\n",
    "sentences = [one_sentence.text.strip() for one_sentence in cleaned_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lionel Andrés \"Leo\" Messi was born in 24 June 1987.',\n",
       " 'Lionel Andrés \"Leo\" Messi is an Argentine professional footballer Lionel Andrés \"Leo\" Messi plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'bear', 'play'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all verbs in the sentences\n",
    "verbs = set()\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\" or token.pos_ == \"AUX\":\n",
    "            verbs.add(token.lemma_)\n",
    "            \n",
    "verbs\n",
    "# verbs2 = [\"earn\"]\n",
    "# # loop on sentences and get the sentences that have verbs woth lemmas in those [earn, have, suspend]\n",
    "# sentences_with_verbs = []\n",
    "# for sentence in sentences:\n",
    "#     doc = nlp(sentence)\n",
    "#     for token in doc:\n",
    "#         if token.lemma_ in verbs2:\n",
    "#             sentences_with_verbs.append(sentence)\n",
    "#             break\n",
    "        \n",
    "# sentences_with_verbs\n",
    "# [earn, have, suspend]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "excludesPerQuestionType = {\n",
    "    \"when\": \"Times\",\n",
    "    \"where\": \"Locations\",\n",
    "    \"who\": \"Subject\",\n",
    "    \"what\": \"Objects\",\n",
    "    \"how\": \"States\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Messi played for Barcelona in 2007\"\n",
    "# answer = \"He talked to him to secure the account.\"\n",
    "# answer = \"The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title.\"\n",
    "# answer = \"As this was the 50th Super Bowl, the league emphasized the golden anniversary with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals ( under which the game would have been known as Super Bowl L ), so that the logo could prominently feature the Arabic numerals 50.\"\n",
    "# answer = \"Aly said yesterday that Ziad was good today.\"\n",
    "# answer = \"Politics: U.N. Secretary General Ban Ki-moon; American political leaders John Hancock, John Adams, John Quincy Adams, Rutherford B. Hayes, Theodore Roosevelt, Franklin D. Roosevelt, John F. Kennedy, Al Gore, George W. Bush and Barack Obama; Chilean President Sebastián Piñera; Colombian President Juan Manuel Santos; Costa Rican President José María Figueres; Mexican Presidents Felipe Calderón, Carlos Salinas de Gortari and Miguel de la Madrid; Mongolian President Tsakhiagiin Elbegdorj; Peruvian President Alejandro Toledo; Taiwanese President Ma Ying-jeou; Canadian Governor General David Lloyd Johnston; Indian Member of Parliament Jayant Sinha; Albanian Prime Minister Fan S. Noli; Canadian Prime Ministers Mackenzie King and Pierre Trudeau; Greek Prime Minister Antonis Samaras; Israeli Prime Minister Benjamin Netanyahu; former Pakistani Prime Minister Benazir Bhutto; U. S. Secretary of Housing and Urban Development Shaun Donovan; Canadian political leader Michael Ignatieff; Pakistani Members of Provincial Assembly Murtaza Bhutto and Sanam Bhutto; Bangladesh Minister of Finance Abul Maal Abdul Muhith; President of Puntland Abdiweli Mohamed Ali; U.S. Ambassador to the European Union Anthony Luzzatto Gardner.\"\n",
    "# answer = 'a scale introduced in 1939.'\n",
    "# answer =  'The length of the Rhine is conventionally measured in Rhine-kilometers (Rheinkilometer ), a scale introduced in 1939 which runs from the Old Rhine Bridge at Constance ( 0 km ) to Hoek van Holland ( 1036.20 km ).'\n",
    "# ans_nlp = nlp(answer)\n",
    "splitted_question = question.split(\" \")\n",
    "question_type = splitted_question[0].lower()\n",
    "question_nlp = nlp(question)\n",
    "if question_nlp[0].ent_type_ == \"DATE\":\n",
    "    question_type = \"when\"\n",
    "\n",
    "# if len(question_nlp) <= 2:\n",
    "#     nlp = spacy.load('en_core_web_md')\n",
    "#     nlp.add_pipe('coreferee')\n",
    "#     question_nlp = nlp(question)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi - PROPN - nsubj - PERSON\n",
      "played - VERB - ROOT - \n",
      "for - ADP - prep - \n",
      "Barcelona - PROPN - pobj - GPE\n",
      "in - ADP - prep - \n",
      "2007 - NUM - pobj - DATE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2c712acd772c46c3aed2abff572ddc3a-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Messi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">played</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Barcelona</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">2007</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c712acd772c46c3aed2abff572ddc3a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c712acd772c46c3aed2abff572ddc3a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c712acd772c46c3aed2abff572ddc3a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c712acd772c46c3aed2abff572ddc3a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c712acd772c46c3aed2abff572ddc3a-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c712acd772c46c3aed2abff572ddc3a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c712acd772c46c3aed2abff572ddc3a-0-3\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c712acd772c46c3aed2abff572ddc3a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c712acd772c46c3aed2abff572ddc3a-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c712acd772c46c3aed2abff572ddc3a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for token in question_nlp:\n",
    "    print(token.text, '-',token.pos_,'-', token.dep_,'-', token.ent_type_)\n",
    "\n",
    "    \n",
    "displacy.render(question_nlp, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in ans_nlp:\n",
    "    \n",
    "#     print(token.text, '-',token.pos_,'-', token.dep_,'-', token.ent_type_)\n",
    "        \n",
    "\n",
    "# displacy.render(ans_nlp, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subjects(sentence):\n",
    "    subjects = {}\n",
    "    verbIdx = 0\n",
    "    for token in sentence:\n",
    "        if token.pos_ == \"VERB\" or token.pos_ == \"AUX\" or token.dep_ == \"ROOT\":\n",
    "            verbIdx += 1\n",
    "            subjectFlag = False\n",
    "            verb = token\n",
    "            for child in token.children:\n",
    "                if child.dep_ in (\"nsubj\", \"csubj\"):\n",
    "                    subtree_tokens = [str(t) for t in child.subtree]\n",
    "                    subjects[token] = (\" \".join(subtree_tokens), verbIdx)\n",
    "                    subjectFlag = True\n",
    "                elif child.dep_ == \"nsubjpass\":\n",
    "                    for child in verb.children:\n",
    "                        if child.dep_ == \"agent\" and len(list(child.children)) > 0:\n",
    "                            subject = [str(t) for t in list(child.children)[0].subtree]\n",
    "                            subject = \" \".join(subject)\n",
    "                            break\n",
    "                        else:\n",
    "                            subject = \"Unknown\"\n",
    "                    subjects[verb] = (subject, verbIdx)\n",
    "                    subjectFlag = True\n",
    "            if not subjectFlag:  # didn't find a normal subject\n",
    "                if token.dep_ in (\"relcl\", \"acl\"):\n",
    "                    subject = str(token.head)\n",
    "                    subjects[token] = (subject, verbIdx)  # should get the subtree of the subject\n",
    "                elif token.dep_ in (\"advcl\", \"conj\"):\n",
    "                    verb = token.head\n",
    "                    \n",
    "                    if verb in subjects:\n",
    "                        subjects[token] = (subjects[verb][0], verbIdx)\n",
    "                    else:\n",
    "                        subjects[token] = (\"Unknown\", verbIdx)  # replace \"Unknown\" with a suitable default\n",
    "                elif token.dep_ == \"xcomp\":\n",
    "                    verb = token.head\n",
    "                    if verb in subjects:\n",
    "                        subjects[token] = (subjects[verb][0], verbIdx)\n",
    "                    else:\n",
    "                        subjects[token] = (\"Unknown\", verbIdx)\n",
    "                    for child in verb.subtree:\n",
    "                        if child.dep_ in (\"dobj\", \"dative\", \"pobj\"):\n",
    "                            subtree_tokens = [str(t) for t in child.subtree]\n",
    "                            subjects[token] = (\" \".join(subtree_tokens), verbIdx)\n",
    "                            break\n",
    "                else:\n",
    "                    subjects[token] = (\"Unknown\", verbIdx)\n",
    "                                        \n",
    "    # (subject, verbIdx, verb)\n",
    "    return [(v[0], k, v[1]) for k, v in subjects.items()]             \n",
    "                            \n",
    "def extract_objects(sentence):\n",
    "    objects = []\n",
    "    verbIdx = 0\n",
    "    for token in sentence:\n",
    "        if token.pos_ == \"VERB\" or token.pos_ == \"AUX\" or token.dep_ == \"ROOT\":\n",
    "            verbIdx += 1\n",
    "            for child in token.children:\n",
    "                if child.dep_ in (\"dobj\", \"dative\", \"attr\", \"oprd\", \"acomp\",\"ccomp\", \"xcomp\", \"nsubjpass\", \"prep\"):\n",
    "                    if child.dep_ == \"prep\":\n",
    "                        for grandchild in child.children:\n",
    "                            if grandchild.dep_ == \"pobj\":\n",
    "                                subtree_tokens = [str(t) for t in grandchild.subtree]\n",
    "                                objects.append((\" \".join(subtree_tokens), token, verbIdx))\n",
    "                    else:\n",
    "                        subtree_tokens = [str(t) for t in child.subtree]\n",
    "                        objects.append((\" \".join(subtree_tokens), token, verbIdx))\n",
    "    return objects\n",
    "\n",
    "def extract_state(sentence):\n",
    "    states = []\n",
    "    verbIdx = 0\n",
    "    for token in sentence:\n",
    "        if token.pos_ ==\"VERB\" or token.pos_ == \"AUX\":\n",
    "            verbIdx += 1\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"prep\":\n",
    "                    subtree_tokens = [str(t) for t in child.subtree]\n",
    "                    states.append(((\" \".join(subtree_tokens), token, verbIdx)))\n",
    "    return states\n",
    "\n",
    "def extract_time(sentence):\n",
    "    times = {}\n",
    "    verbIdx = 0\n",
    "    year_pattern = re.compile(r'\\b\\d{4}\\b')  # matches any four-digit number\n",
    "    for token in sentence:\n",
    "        if token.pos_ == \"VERB\" or token.pos_ == \"AUX\" or token.dep_ == \"ROOT\":\n",
    "            verbIdx += 1\n",
    "            for child in token.subtree:\n",
    "                if child.ent_type_ == \"DATE\" or child.ent_type_ == \"TIME\":\n",
    "                    times[child.text] = (token, verbIdx)\n",
    "                elif year_pattern.search(child.text):\n",
    "                    year = year_pattern.search(child.text).group()\n",
    "                    times[year] = (token, verbIdx)\n",
    "    return [(k, v[0], v[1]) for k, v in times.items()]\n",
    "\n",
    "def extract_location(sentence):\n",
    "    locations = {}\n",
    "    verbIdx = 0\n",
    "    for token in sentence:\n",
    "        if token.pos_ == \"VERB\" or token.pos_ == \"AUX\" or token.dep_ == \"ROOT\":\n",
    "            verbIdx += 1\n",
    "            for child in token.subtree:\n",
    "                if child.ent_type_ in (\"GPE\", \"LOC\", \"FAC\"):\n",
    "                    locations[child.text] = (token, verbIdx)\n",
    "                    \n",
    "    return [(k, v[0], v[1]) for k, v in locations.items()]\n",
    "                    \n",
    "\n",
    "def extract_facts(sentence):\n",
    "    sentence = nlp(sentence)\n",
    "    states = extract_state(sentence)\n",
    "    subjects = extract_subjects(sentence)\n",
    "    objects = extract_objects(sentence)\n",
    "    times = extract_time(sentence)\n",
    "    locations = extract_location(sentence)\n",
    "    print(\"Subjects: \",subjects, objects)\n",
    "    print(\"states: \" ,states, \"times: \", times,\"locations: \", locations)\n",
    "    \n",
    "    facts = pd.DataFrame(columns=[\"Subject\", \"Relation\", \"verbIdx\", \"Objects\", \"States\", \"Times\", \"Locations\"])\n",
    "    \n",
    "    for subject in subjects: #(Aly, is, 1), (Ziad,is, 2) \n",
    "        currentSubject = subject[0]\n",
    "        verb = subject[1].lemma_\n",
    "        verbIdx = subject[2]\n",
    "        mask = (facts['Subject'] != currentSubject) | (facts['Relation'] != verb)\n",
    "        if mask.all():\n",
    "            new_row = pd.DataFrame([{\"Subject\": currentSubject, \"Relation\": verb, \"verbIdx\": verbIdx, \"Objects\": [], \"States\": [], \"Times\": [], \"Locations\": []}])\n",
    "            facts = pd.concat([facts, new_row], ignore_index=True)\n",
    "\n",
    "    for obj in objects: #(happy, is, 1), (good, is, 2)\n",
    "        currentObj = obj[0]\n",
    "        verb = obj[1].lemma_\n",
    "        verbIdx = obj[2]\n",
    "        mask = (facts['Relation'] == verb) & (facts['verbIdx'] == verbIdx)\n",
    "        if mask.any():\n",
    "            oldObjects = list(facts.loc[mask, \"Objects\"].values[0])\n",
    "            oldObjects.append(currentObj)\n",
    "            for idx in facts.loc[mask].index:\n",
    "                facts.at[idx, \"Objects\"] = oldObjects\n",
    "            \n",
    "    for state in states:\n",
    "        currentState = state[0]\n",
    "        verb = state[1].lemma_\n",
    "        verbIdx = state[2]\n",
    "        mask = (facts['Relation'] == verb) & (facts['verbIdx'] == verbIdx)\n",
    "        if mask.any():\n",
    "            oldStates = list(facts.loc[mask, \"States\"].values[0])\n",
    "            oldStates.append(currentState)\n",
    "            for idx in facts.loc[mask].index:\n",
    "                facts.at[idx, \"States\"] = oldStates\n",
    "            \n",
    "    for time in times:\n",
    "        currentTime = time[0]\n",
    "        verb = time[1].lemma_\n",
    "        verbIdx = time[2]\n",
    "        mask = (facts['Relation'] == verb) & (facts['verbIdx'] == verbIdx)\n",
    "        if mask.any():\n",
    "            oldTimes = list(facts.loc[mask, \"Times\"].values[0])\n",
    "            oldTimes.append(currentTime)\n",
    "            for idx in facts.loc[mask].index:\n",
    "                facts.at[idx, \"Times\"] = oldTimes\n",
    "            \n",
    "    for location in locations:\n",
    "        currentLocation = location[0]\n",
    "        verb = location[1].lemma_\n",
    "        verbIdx = location[2]\n",
    "        mask = (facts['Relation'] == verb) & (facts['verbIdx'] == verbIdx)\n",
    "        if mask.any():\n",
    "            oldLocations = list(facts.loc[mask, \"Locations\"].values[0])\n",
    "            oldLocations.append(currentLocation)\n",
    "            for idx in facts.loc[mask].index:\n",
    "                facts.at[idx, \"Locations\"] = oldLocations\n",
    "            \n",
    "    facts = facts.drop(columns=[\"verbIdx\"])\n",
    "    return facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_facts(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects:  [('Messi', played, 1)] [('Barcelona', played, 1), ('2007', played, 1)]\n",
      "states:  [('for Barcelona', played, 1), ('in 2007', played, 1)] times:  [('2007', played, 1)] locations:  [('Barcelona', played, 1)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Objects</th>\n",
       "      <th>States</th>\n",
       "      <th>Times</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Messi</td>\n",
       "      <td>play</td>\n",
       "      <td>[Barcelona, 2007]</td>\n",
       "      <td>[for Barcelona, in 2007]</td>\n",
       "      <td>[2007]</td>\n",
       "      <td>[Barcelona]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Relation            Objects                    States   Times  \\\n",
       "0   Messi     play  [Barcelona, 2007]  [for Barcelona, in 2007]  [2007]   \n",
       "\n",
       "     Locations  \n",
       "0  [Barcelona]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionDF = extract_facts(question)\n",
    "#check the length of the questionDF\n",
    "if len(questionDF) == 0:\n",
    "    print(\"No facts found in the question\")\n",
    "    new_row = pd.DataFrame([{\"Subject\": question_nlp.text, \"Relation\": question_nlp.text, \"Objects\": question_nlp.text, \"States\": [question_nlp.text], \"Times\": [question_nlp.text], \"Locations\": [question_nlp.text]}])\n",
    "    questionDF = pd.concat([questionDF, new_row], ignore_index=True)\n",
    "            \n",
    "questionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sentences_facts(sentences):\n",
    "    all_facts = pd.DataFrame(columns=[\"Subject\", \"Relation\", \"Objects\", \"States\", \"Times\", \"Locations\"])\n",
    "    for sentence in sentences:\n",
    "        facts = extract_facts(sentence)\n",
    "        all_facts = pd.concat([all_facts, facts])\n",
    "    all_facts = all_facts.groupby([\"Subject\", \"Relation\"], as_index=False).agg({\n",
    "        \"Objects\": lambda x: [item for sublist in x for item in sublist],\n",
    "        \"States\": lambda x: [item for sublist in x for item in sublist],\n",
    "        \"Times\": lambda x: [item for sublist in x for item in sublist],\n",
    "        \"Locations\": lambda x: [item for sublist in x for item in sublist]\n",
    "    })\n",
    "    return all_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects:  [('Unknown', was, 1), ('Unknown', born, 2)] [('Lionel Andrés \"Leo\" Messi', born, 2)]\n",
      "states:  [('in 24 June 1987', born, 2)] times:  [('24 June 1987', born, 2)] locations:  []\n",
      "Subjects:  [('Lionel Andrés \"Leo\" Messi', is, 1), ('Lionel Andrés \"Leo\" Messi', plays, 2)] [('an Argentine professional footballer Lionel Andrés \"Leo\" Messi plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team', is, 1)]\n",
      "states:  [('as a forward', plays, 2), ('for', plays, 2)] times:  [] locations:  []\n"
     ]
    }
   ],
   "source": [
    "factsDF = join_sentences_facts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Objects</th>\n",
       "      <th>States</th>\n",
       "      <th>Times</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lionel Andrés \"Leo\" Messi</td>\n",
       "      <td>be</td>\n",
       "      <td>[an Argentine professional footballer Lionel A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lionel Andrés \"Leo\" Messi</td>\n",
       "      <td>play</td>\n",
       "      <td>[]</td>\n",
       "      <td>[as a forward, for]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>be</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>bear</td>\n",
       "      <td>[Lionel Andrés \"Leo\" Messi]</td>\n",
       "      <td>[in 24 June 1987]</td>\n",
       "      <td>[24 June 1987]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Subject Relation  \\\n",
       "0  Lionel Andrés \"Leo\" Messi       be   \n",
       "1  Lionel Andrés \"Leo\" Messi     play   \n",
       "2                    Unknown       be   \n",
       "3                    Unknown     bear   \n",
       "\n",
       "                                             Objects               States  \\\n",
       "0  [an Argentine professional footballer Lionel A...                   []   \n",
       "1                                                 []  [as a forward, for]   \n",
       "2                                                 []                   []   \n",
       "3                        [Lionel Andrés \"Leo\" Messi]    [in 24 June 1987]   \n",
       "\n",
       "            Times Locations  \n",
       "0              []        []  \n",
       "1              []        []  \n",
       "2              []        []  \n",
       "3  [24 June 1987]        []  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_subject_relation(factsDF, isQuestion = True):\n",
    "    if not isQuestion:\n",
    "        factsDF = factsDF[~((factsDF[\"Subject\"] == \"Unknown\") & (factsDF[\"Objects\"].apply(len) == 0) & (factsDF[\"States\"].apply(len) == 0) & (factsDF[\"Times\"].apply(len) == 0) & (factsDF[\"Locations\"].apply(len) == 0))]\n",
    "        factsDF = factsDF.reset_index(drop=True)\n",
    "\n",
    "    for index, row in factsDF.iterrows():\n",
    "        factsDF.loc[index, \"Subject\"] = [row['Subject']]\n",
    "        factsDF.loc[index, \"Relation\"] = [row['Relation']]\n",
    "    return factsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFactsDF = change_subject_relation(factsDF, False)\n",
    "#save in csv\n",
    "newFactsDF.to_csv(\"facts2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Objects</th>\n",
       "      <th>States</th>\n",
       "      <th>Times</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Lionel Andrés \"Leo\" Messi]</td>\n",
       "      <td>[be]</td>\n",
       "      <td>[an Argentine professional footballer Lionel A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Lionel Andrés \"Leo\" Messi]</td>\n",
       "      <td>[play]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[as a forward, for]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Unknown]</td>\n",
       "      <td>[bear]</td>\n",
       "      <td>[Lionel Andrés \"Leo\" Messi]</td>\n",
       "      <td>[in 24 June 1987]</td>\n",
       "      <td>[24 June 1987]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Subject Relation  \\\n",
       "0  [Lionel Andrés \"Leo\" Messi]     [be]   \n",
       "1  [Lionel Andrés \"Leo\" Messi]   [play]   \n",
       "2                    [Unknown]   [bear]   \n",
       "\n",
       "                                             Objects               States  \\\n",
       "0  [an Argentine professional footballer Lionel A...                   []   \n",
       "1                                                 []  [as a forward, for]   \n",
       "2                        [Lionel Andrés \"Leo\" Messi]    [in 24 June 1987]   \n",
       "\n",
       "            Times Locations  \n",
       "0              []        []  \n",
       "1              []        []  \n",
       "2  [24 June 1987]        []  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFactsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Objects</th>\n",
       "      <th>States</th>\n",
       "      <th>Times</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Messi]</td>\n",
       "      <td>[play]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[for Barcelona, in Spain]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Barcelona, Spain]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject Relation Objects                     States Times  \\\n",
       "0  [Messi]   [play]      []  [for Barcelona, in Spain]    []   \n",
       "\n",
       "            Locations  \n",
       "0  [Barcelona, Spain]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newQuestionDF = change_subject_relation(questionDF, False)\n",
    "newQuestionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(factRow, questionRow, column):\n",
    "    if len(factRow[column]) == 0 or len(questionRow[column]) == 0 or factRow[column] == [\"Unknown\"] or questionRow[column] == [\"Unknown\"]:\n",
    "        return 0\n",
    "    columnString = \" \".join(factRow[column])\n",
    "    questionString = \" \".join(questionRow[column])\n",
    "    embeddingFact = model.encode(columnString)\n",
    "    embeddingQuestion = model.encode(questionString)\n",
    "    return util.cos_sim(embeddingFact, embeddingQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(factsDf, questionFact, excludeColumns=[]):\n",
    "    score = 0\n",
    "    maxFactIdx = 0\n",
    "    columnNames = [\"Subject\",\"Relation\", \"Objects\", \"States\", \"Times\", \"Locations\"]\n",
    "    for column in excludeColumns:\n",
    "        columnNames.remove(column)\n",
    "    for factIdx, factRow in factsDf.iterrows():\n",
    "        currScore = 0\n",
    "        for _, questionRow in questionFact.iterrows():\n",
    "            if len(factRow[excludeColumns[0]]) == 0 or factRow[excludeColumns[0]] == [\"Unknown\"]:\n",
    "                continue\n",
    "            for column in columnNames:\n",
    "                currScore += similarity(factRow, questionRow, column)\n",
    "        if currScore > score:\n",
    "            score = currScore\n",
    "            maxFactIdx = factIdx\n",
    "    return maxFactIdx, score\n",
    "\n",
    "# def cost_function(factsDf, questionFact, excludeColumns=[]):\n",
    "#     cost = 0\n",
    "#     maxFactIdx = 0\n",
    "#     columnNames = [\"Subject\",\"Relation\", \"Objects\", \"States\", \"Times\", \"Locations\"]\n",
    "#     for column in excludeColumns:\n",
    "#         columnNames.remove(column)\n",
    "#     for factIdx, factRow in factsDf.iterrows():\n",
    "#         currCost = 0\n",
    "#         for _, questionRow in questionFact.iterrows():\n",
    "#             isExcluded = False\n",
    "#             if len(factRow[excludeColumns[0]]) == 0:\n",
    "#                 if len(factRow[\"States\"]) == 0:\n",
    "#                     continue\n",
    "#                 isExcluded = True\n",
    "#             for column in columnNames:\n",
    "#                 if isExcluded and column == \"States\":\n",
    "#                     continue\n",
    "#                 currCost += similarity(factRow, questionRow, column)\n",
    "#         currCost -= currCost * 0.6 * isExcluded\n",
    "#         if currCost > cost:\n",
    "#             cost = currCost\n",
    "#             maxFactIdx = factIdx\n",
    "#     return maxFactIdx, cost        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Objects</th>\n",
       "      <th>States</th>\n",
       "      <th>Times</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Messi]</td>\n",
       "      <td>[play]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[for Barcelona, in Spain]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Barcelona, Spain]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject Relation Objects                     States Times  \\\n",
       "0  [Messi]   [play]      []  [for Barcelona, in Spain]    []   \n",
       "\n",
       "            Locations  \n",
       "0  [Barcelona, Spain]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newQuestionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'messi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m correctIdx, _ \u001b[38;5;241m=\u001b[39m cost_function(newFactsDF, newQuestionDF, excludeColumns\u001b[38;5;241m=\u001b[39m[excludesPerQuestionType[question_type]])\n\u001b[0;32m      2\u001b[0m WhenAnswer \u001b[38;5;241m=\u001b[39m newFactsDF\u001b[38;5;241m.\u001b[39mloc[correctIdx, excludesPerQuestionType[question_type]]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WhenAnswer \u001b[38;5;241m==\u001b[39m []:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'messi'"
     ]
    }
   ],
   "source": [
    "correctIdx, _ = cost_function(newFactsDF, newQuestionDF, excludeColumns=[excludesPerQuestionType[question_type]])\n",
    "WhenAnswer = newFactsDF.loc[correctIdx, excludesPerQuestionType[question_type]]\n",
    "if WhenAnswer == []:\n",
    "    WhenAnswer = newFactsDF.loc[correctIdx, \"States\"]    \n",
    "\" \".join(WhenAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: 0.2557494044303894\n"
     ]
    }
   ],
   "source": [
    "emb1 = model.encode(\"did Lev's Stadium open\")\n",
    "emb2 = model.encode(\"open\")\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.14 + 0.38\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "for\n"
     ]
    }
   ],
   "source": [
    "text = \"played for\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe(\"ner\").labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
