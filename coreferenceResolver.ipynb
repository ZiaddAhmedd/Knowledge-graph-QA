{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<coreferee.manager.CorefereeBroker at 0x212bf747a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import coreferee, spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "nlp.add_pipe(\"merge_noun_chunks\")\n",
    "nlp.add_pipe('coreferee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_coreference(text):\n",
    "    doc = nlp(text)\n",
    "    doc_list = list(doc)\n",
    "    doc._.coref_chains.print()\n",
    "    resolving_indecies = []\n",
    "    for _,item in enumerate(doc._.coref_chains):\n",
    "        resolving_indecies.extend(item)\n",
    "        \n",
    "    for word in resolving_indecies:\n",
    "        new_word = \"\"\n",
    "        for index in word:\n",
    "            if doc[index]._.coref_chains.resolve(doc[index]) is not None:\n",
    "                temp = []\n",
    "                for item in doc._.coref_chains.resolve(doc[index]):\n",
    "                    temp.append(str(item))\n",
    "                new_word = \", \".join(temp)\n",
    "            \n",
    "                doc_list[index] = new_word\n",
    "\n",
    "    final_doc = []\n",
    "    for item in doc_list:\n",
    "        final_doc.append(str(item))\n",
    "    return \" \".join(final_doc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp2 = spacy.load('en_core_web_md')\n",
    "# nlp2.add_pipe(\"merge_entities\")\n",
    "# nlp2.add_pipe(\"merge_noun_chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Although he was very busy with his work, Peter had had enough of it. He and his wife decided they needed a holiday. They travelled to Spain because they loved the country very much.\"\n",
    "# text = \"Leo Messi the smartest player in the world scored 1000 goals. He is the best player\"\n",
    "# text = \"the actor said that the queen was a too generous person. He also mentioned that she is a great leader.\" \n",
    "text = \"Although she was very busy with his work, Elaizbeth was a great leader, she was the first queen of England\"\n",
    "# text =\"\"\"\n",
    "# Lionel Andrés \"Leo\" Messi was born in 24 June 1987 is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team.\n",
    "# Widely regarded as one of the greatest players of all time, Messi has won a record eight Ballon d'Or awards, a record six European Golden Shoes, and was named the world's best player for a record eight times by FIFA.\n",
    "# Until 2021, he had spent his entire professional career with Barcelona, where he won a club-record 34 trophies, including ten La Liga titles, seven Copa del Rey titles, and the UEFA Champions League four times.\n",
    "# With his country, he won the 2021 Copa América and the 2022 FIFA World Cup. A prolific goalscorer and creative playmaker, Messi holds the records for most goals (474), hat-tricks (36), and assists in La Liga (192). He has the most international goals by a South American male (106). Messi has scored over 800 senior career goals for club and country, and the most goals for a single club.\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Although she was very busy with his work, Elaizbeth was a great leader, she was the first queen of England]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = nlp(text)\n",
    "list(test.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: she(1), Elaizbeth(8), she(12)\n",
      "Although Elaizbeth was very busy with his work , Elaizbeth was a great leader , Elaizbeth was the first queen of England\n"
     ]
    }
   ],
   "source": [
    "text = resolve_coreference(text)\n",
    "print(text)\n",
    "# doc = nlp2(text)\n",
    "# for token in doc:\n",
    "#     print(token.text, '-',token.pos_,'-', token.dep_,'-', token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.36.0\n",
      "  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
      "     ---------------------------------------- 0.0/126.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/126.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/126.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/126.8 kB ? eta -:--:--\n",
      "     ----------------------- ------------- 81.9/126.8 kB 573.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 126.8/126.8 kB 677.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.36.0)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.0)\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from transformers==4.36.0) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.36.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from requests->transformers==4.36.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from requests->transformers==4.36.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from requests->transformers==4.36.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zisak\\anaconda3\\lib\\site-packages (from requests->transformers==4.36.0) (2024.2.2)\n",
      "Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
      "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/8.2 MB 7.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.3/8.2 MB 3.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.4/8.2 MB 3.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/8.2 MB 3.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/8.2 MB 3.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/8.2 MB 3.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.1/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.7/8.2 MB 3.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.9/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.0/8.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.2/8.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.8/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.1/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.3/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.5/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.6/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.8/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.0/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.2/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.3/8.2 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.4/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.4/8.2 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.5/8.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.8/8.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.9/8.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.1/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.4/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.6/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.7/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.9/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.1/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.3/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.5/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.7/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.9/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.0/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.2/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.3/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.5/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.7/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.1/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.2/8.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.2/8.2 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 143.4/401.2 kB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 276.5/401.2 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.2/401.2 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.0/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.0/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 71.7/316.1 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 174.1/316.1 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 316.1/316.1 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.17.0\n",
      "    Uninstalling transformers-4.17.0:\n",
      "      Successfully uninstalled transformers-4.17.0\n",
      "Successfully installed fsspec-2024.5.0 huggingface-hub-0.23.0 tokenizers-0.15.2 transformers-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.5.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.36.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zisak\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
